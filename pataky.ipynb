{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_gnd = pd.read_csv('data/pataky-gnd-gefunden-03-03-24.csv')\n",
    "df_cleaned_name = pd.read_csv('data/pataky/cleaned-namelist-pataky-all.csv')\n",
    "df_biographie = pd.read_csv('data/pataky/pataky-biographie-bibliographie.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_gnd.columns)\n",
    "print(df_cleaned_name.columns)\n",
    "print(df_biographie.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_gnd_cleaned = pd.merge(\n",
    "    df_gnd,\n",
    "    df_cleaned_name,\n",
    "    left_on='name',\n",
    "    right_on='Name Vorname',\n",
    "    how='inner'  # Use 'inner' to keep only matching rows\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged = pd.merge(\n",
    "    merged_gnd_cleaned,\n",
    "    df_biographie,\n",
    "    left_on='Original',\n",
    "    right_on='Name',\n",
    "    how='inner' \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(final_merged))\n",
    "final_merged = final_merged.drop_duplicates()\n",
    "print(len(final_merged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged.to_csv('pataky-gnd-biblio-bio.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pataky = pd.read_csv('data/pataky/pataky-gnd-biblio-bio.csv')\n",
    "print(len(df_pataky))\n",
    "df_pataky = df_pataky.drop_duplicates()\n",
    "print(len(df_pataky))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pataky = pd.read_csv('data/pataky/pataky-gnd-biblio-bio.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pataky_flattened = pd.read_csv('data/pataky/pataky-flattened.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### try regex aus biography Nach- und Vorname rausziehen -> klappt\n",
    "\n",
    "# test1 = 'Nowotny, Isabella, Ps. Ida Klein, Herzen, Prag, Kleinseite'\n",
    "# test2 = 'Bistram, Baronesse Ottilie von, Wiesbaden, Nicolasstr. 26, wurde am'\n",
    "test3 = df_pataky_flattened['biography_1']\n",
    "def use_regex(input_text):\n",
    "    pattern = re.compile(r\"(\\w+(?:[\\s-]\\w+)*(?:\\s+von\\s+\\w+)?),\\s+((?:\\w+\\.?\\s+)*\\w+)\", re.IGNORECASE)    \n",
    "    match = pattern.match(input_text)\n",
    "    if match:\n",
    "        # input_text = input_text.replace(f\"{match.group(1)}, {match.group(2)}\", \"\")\n",
    "        return f\"{match.group(1)}, {match.group(2)}\"\n",
    "    return None\n",
    "# mistakes = []\n",
    "# for entry in test3:\n",
    "#     res = use_regex(entry)\n",
    "#     if res == None:\n",
    "#         mistakes.append(entry)\n",
    "# df_pataky_flattened['name'] = df_pataky_flattened['biography_1'].apply(use_regex)\n",
    "# with open('mistakes.txt', 'w', encoding='utf-8') as f:\n",
    "#     for line in mistakes:\n",
    "#         f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in enumerate(df_pataky_flattened.iterrows()):\n",
    "    tmp = df_pataky_flattened['name'].iloc[index]\n",
    "    # Check if tmp is a string and not None/NaN\n",
    "    if isinstance(tmp, str) and tmp in df_pataky_flattened['biography_1'].iloc[index]:\n",
    "        df_pataky_flattened.at[index, 'biography_1'] = df_pataky_flattened['biography_1'].iloc[index].replace(tmp, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pataky_flattened.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sprachliste = pd.read_csv('data/pataky/sprachen.csv')\n",
    "print(sprachliste['Sprache'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## explizite Sprachnennungen in Biographie finden\n",
    "\n",
    "def use_regex_sprachen(input_text, sprachliste):\n",
    "    return [phrase for phrase in sprachliste['Sprache'] if phrase.lower() in input_text.lower()]\n",
    "\n",
    "explizite_sprachen = {}\n",
    "for index, row in df_pataky.iterrows():\n",
    "    tmp = use_regex_sprachen(row['biography'], sprachliste)\n",
    "    if tmp:\n",
    "        explizite_sprachen[row['gnd']] = tmp\n",
    "print(explizite_sprachen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (pd.DataFrame.from_dict(data=explizite_sprachen, orient='index')\n",
    "#    .to_csv('data/pataky/pataky_explizite_sprachen_bio.csv', header=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "unique_ids = df_pataky['gnd'].unique()\n",
    "\n",
    "for gnd_id in unique_ids:\n",
    "    group = df_pataky[df_pataky['gnd'] == gnd_id].reset_index(drop=True)\n",
    "    \n",
    "    row_dict = {'gnd': gnd_id}\n",
    "    \n",
    "    for i, row in group.iterrows():\n",
    "        suffix = i + 1\n",
    "        for col in group.columns:\n",
    "            if col != 'gnd': \n",
    "                row_dict[f\"{col}_{suffix}\"] = row[col]\n",
    "    \n",
    "    result.append(row_dict)\n",
    "\n",
    "df_wide = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WERKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###TEST\n",
    "\n",
    "biblio = df_pataky['bibliography'][:10]\n",
    "print(biblio)\n",
    "#split_sample = sample.split('–')\n",
    "for item in biblio:\n",
    "    split_sample = [\n",
    "        part.lstrip().replace(\"‒\", \"\").strip() \n",
    "            for part in item.split('–')\n",
    "        ]\n",
    "print(split_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bibliography(entry):\n",
    "    raw_entries = re.split(r'\\s*‒\\s*(?=[A-Z])', entry)\n",
    "    # Clean the entries\n",
    "    parsed_entries = [\n",
    "        entry.strip() \n",
    "        for entry in raw_entries \n",
    "        if entry.strip()  \n",
    "    ]\n",
    "    \n",
    "    return parsed_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnd_biblio = {}\n",
    "for i in range(len(df_pataky)):\n",
    "    temp = df_pataky['bibliography'].iloc[i]\n",
    "    gnd = df_pataky['gnd'].iloc[i]\n",
    "    \n",
    "    if temp == '.':\n",
    "        continue\n",
    "    else:\n",
    "        gnd_biblio[gnd] = parse_bibliography(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for key, values in gnd_biblio.items():\n",
    "    for value in values:\n",
    "        rows.append((key, value))\n",
    "\n",
    "with open('data/pataky/gnd-werke.csv', 'w', encoding='utf-8', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['GND', 'Werk'])  \n",
    "    writer.writerows(rows) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_werke = pd.read_csv('data/pataky/gnd-werke.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uebersetzungen = [{df_werke.loc[index, 'gnd']: werk} \n",
    "                  for index, werk in df_werke['werk'].items() \n",
    "                  if re.search(r'übers\\w*', werk.lower())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"uebersetzungen.csv\", mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the header\n",
    "    writer.writerow(['gnd', 'werk'])\n",
    "\n",
    "    # Write the data\n",
    "    for item in uebersetzungen:\n",
    "        for gnd, werk in item.items():\n",
    "            writer.writerow([gnd, werk])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pseudonyme und variante Namen matchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verweise_pseudonyme_list = ['Werke: s.', 'Biographie s.', 'Biographie und Werke s.', 'Ps.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_regex(input_text, phrases):\n",
    "    phrases_pattern = '|'.join(re.escape(phrase) for phrase in phrases)\n",
    "    pattern = re.compile(\n",
    "        rf\"({phrases_pattern})\\s(?:([A-Za-z]+),\\s([A-Za-z]+)|([A-Za-z]+)\\s([A-Za-z]+))\\.\",\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    match = pattern.search(input_text)\n",
    "    print(match)\n",
    "    if match:\n",
    "        if match.group(2):\n",
    "            return match.group(3) + \" \" + match.group(2)\n",
    "        else:\n",
    "            return match.group(4) + \" \" + match.group(5)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"*Beaulieu, Gertraut Châles de, Ps. G. v. Beaulieu, Charlottenburg, Goethestrasse 7, entstammt einer französischen Emigrantenfamilie, Tochter eines Geheimen Oberjustizrats zu Berlin, geboren am 17. März 1846 zu Frankfurt a. O. Sie verbrachte lange Zeit auf Reisen und besuchte u.a. Italien, Griechenland, Spanien, Frankreich, Dänemark, Holland und Belgien, schriftstellerisch thätig war sie anfangs als Übersetzerin von Korrespondenzen ins Englische für den »Melbourne Argus« in Australien, die »Hour« in London. Schrieb für den »Capitan Fracassa«, Zeitung in Rom; dann redigierte sie 4 1/ 2 Iahr hindurch selbständig »Das humoristische Deutschland«, jetzt korrespondiert sie für das »Dagblad van Zuid-Holland en's Gravenhage«. Sie schrieb für »Westermanns Monatshefte« Reiseskizzen, ferner Skizzen, Novellen, Feuilletons für die »Nationalzeitung«, die »Vossische Zeitung«, »Zukunft«, »Über Land und Meer«, »Deutsche Revue«, »Illustrierte Zeitung« in Leipzig, »Kölnische Zeitung« u.a.m.\"\n",
    "use_regex(test, verweise_pseudonyme_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_verweise = {}\n",
    "for index, row in df_pataky[130:140].iterrows():\n",
    "    tmp = use_regex(row['biography'], verweise_pseudonyme_list)\n",
    "    if tmp:\n",
    "        matched_verweise[row['name']] = tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Orte zuordnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pataky = pd.read_csv('data/pataky/pataky_ohne_gnd.csv')\n",
    "\n",
    "# list_orte = []\n",
    "# with open(\"data/pataky/pataky_locations.txt\", encoding=\"utf-8\") as fp:  \n",
    "#    for line in fp:\n",
    "#        list_orte.extend(line.strip().split('\\n'))\n",
    "       \n",
    "tmp = pd.read_csv('data/pataky/orte-geonames.csv')\n",
    "list_orte = list(tmp['Ortsname'])       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pataky_wohnorte = []\n",
    "\n",
    "for index, text in enumerate(df_pataky['biography']):\n",
    "    locations_per_author = []\n",
    "    for ort in list_orte:\n",
    "        if ort in text:\n",
    "            locations_per_author.append(ort)\n",
    "    pataky_wohnorte.append({df_pataky['identifier'].iloc[index] : locations_per_author})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "## [{x1 : [y1, y2, y3]}, {x1 : [z1, z2]},...] -> [{x1 : [[y1, y2, y3, z1, z2]}]\n",
    "\n",
    "combined_dict = defaultdict(list)\n",
    "for entry in pataky_wohnorte:\n",
    "    for key, value in entry.items():\n",
    "        combined_dict[key].extend(value)\n",
    "        \n",
    "pataky_wohnorte = [{key: values} for key, values in combined_dict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/pataky/pataky_unidentified_wohnorte.csv\", mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the header\n",
    "    writer.writerow(['gnd', 'wohnort'])\n",
    "\n",
    "    # Write the data\n",
    "    for item in pataky_wohnorte:\n",
    "        for gnd, wohnort in item.items():\n",
    "            writer.writerow([gnd, wohnort])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def api_request_geonames(place_name):\n",
    "    url = \"http://api.geonames.org/searchJSON\"\n",
    "    params = {\n",
    "        'q': place_name,\n",
    "        'maxRows': 10,\n",
    "        'username': 'kitkatja'\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        if 'geonames' in data:\n",
    "            return [place['geonameId'] for place in data['geonames']]\n",
    "        else:\n",
    "            print(\"No results found\")\n",
    "            return []\n",
    "    except requests.RequestException as e:\n",
    "        print(\"Request failed:\", e)\n",
    "        return []\n",
    "    except ValueError as e:\n",
    "        print(\"Failed to parse JSON:\", e)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_with_geonames = {}  \n",
    "\n",
    "place_list = list_orte  \n",
    "for place in place_list:\n",
    "    result = api_request_geonames(place)  \n",
    "    if result:  \n",
    "        location_with_geonames[place] = result[0]  \n",
    "    else:\n",
    "        location_with_geonames[place] = 'NaN'  \n",
    "\n",
    "print(location_with_geonames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/pataky/orte-geonames.csv', 'w', encoding='utf-8') as csv_file:  \n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in location_with_geonames.items():\n",
    "       writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEI mit placeName tags anreichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ortsliste_pataky = pd.read_csv('data/pataky/orte-geonames.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## iteriert durch die einzelnen Paragraphen des TEI und sucht in jedem nach den gespeicherten Orten in der Liste\n",
    "## wenn Ort gefunden wird, wird <placeName /> drum geschrieben\n",
    "## paragraph wird dann als etree XML object zurück ins TEI geschrieben\n",
    "## Problem dabei: es muss in ein tag eingebettet sein, um als XML object erkannt zu werden -> doppelte <p> Auszeichnung im TEI -> nicht valide\n",
    "## Lösung: nach Abschluss des Parsens die doppelten Tags manuell durch find+replace entfernen\n",
    "try:\n",
    "    tree = etree.parse('data/pataky/tei-xml/pataky_lexikon02.xml')\n",
    "    root = tree.getroot()\n",
    "    namespace = {\"tei\": \"http://www.tei-c.org/ns/1.0\"}\n",
    "    text_elements = root.xpath(\"//tei:body//tei:p\", namespaces=namespace)\n",
    "    place_element = etree.Element(\"placeName\")\n",
    "\n",
    "    for paragraph in text_elements:\n",
    "        full_text = \" \".join(text.strip() for text in paragraph.itertext()).replace(\"\\n\", \" \").strip()\n",
    "        full_text = re.sub(r'\\s+', ' ', full_text).strip()\n",
    "\n",
    "        #print(f\"Parsing paragraph: {full_text}\")         \n",
    "        for location in ortsliste_pataky['Ortsname']:\n",
    "            if location in full_text:\n",
    "                pattern = rf'\\b{re.escape(location)}\\b'\n",
    "                full_text = re.sub(pattern, fr'<placeName xmlns=\"http://www.tei-c.org/ns/1.0\">{location}</placeName>', full_text)\n",
    "        paragraph.clear() \n",
    "        paragraph.append(etree.XML(f\"<p>{full_text}</p>\"))\n",
    "\n",
    "    tree.write('data/pataky/tei-xml/pataky_lexikon01_modified-test.xml', pretty_print=True, encoding='UTF-8')            \n",
    "except etree.XMLSyntaxError as e:\n",
    "       print(f\"XML parsing error:{full_text}, {e}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Please check the file path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Autorinnen ohne gnd finden\n",
    "\n",
    "df_ohnegnd = pd.read_csv('data/pataky/pataky-not-found-18-5-24.csv')\n",
    "df_pataky = pd.read_csv('data/pataky/pataky-gnd-biblio-bio.csv')\n",
    "result = df_ohnegnd[~df_ohnegnd['Name'].isin(df_pataky['name'])]\n",
    "\n",
    "merged_gnd_cleaned = pd.merge(\n",
    "    df_ohnegnd,\n",
    "    df_cleaned_name,\n",
    "    left_on='Name',\n",
    "    right_on='Name Vorname',\n",
    "    how='inner'  # Use 'inner' to keep only matching rows\n",
    ")\n",
    "\n",
    "final_merged = pd.merge(\n",
    "    merged_gnd_cleaned,\n",
    "    df_biographie,\n",
    "    left_on='Original',\n",
    "    right_on='Name',\n",
    "    how='inner' \n",
    ")\n",
    "final_merged.to_csv('pataky_ohne_gnd.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Attribute zu persName hinzufügen\n",
    "\n",
    "identifier_df = pd.read_csv('data/pataky/pataky-alle-identifier.csv')\n",
    "identifier_df = identifier_df.drop_duplicates()\n",
    "\n",
    "identifier_list = identifier_df.to_dict(orient=\"records\")\n",
    "\n",
    "name_id_map = {\n",
    "    entry[\"name\"]: f\"id_{entry['identifier']}\" for entry in identifier_list\n",
    "}\n",
    "\n",
    "tree = etree.parse(\"data/pataky/tei-xml/pataky_lexikon02_modified.xml\")\n",
    "root = tree.getroot()\n",
    "\n",
    "ns = {'tei': 'http://www.tei-c.org/ns/1.0'}\n",
    "\n",
    "for pers in root.xpath(\".//tei:persName\", namespaces=ns):\n",
    "    name_text = pers.text.strip() if pers.text else \"\"\n",
    "    if name_text in name_id_map:\n",
    "        pers.attrib['{http://www.w3.org/XML/1998/namespace}id'] = name_id_map[name_text]\n",
    "\n",
    "tree.write(\"data/pataky/tei-xml/pataky_lexikon02_attributes.xml\", encoding=\"utf-8\", xml_declaration=True, pretty_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
